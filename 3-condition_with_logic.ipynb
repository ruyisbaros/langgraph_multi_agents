{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END, MessageGraph\n",
    "from IPython.display import display, Image\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "import operator\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "llm = ChatGroq(\n",
    "    # model=\"llama3-groq-70b-8192-tool-use-preview\",\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "#embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "config = {\"configurable\": {\"thread_id\": 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chatModel = ChatOpenAI(base_url=\"http://ai.mtcl.lan:11436/v1\", api_key=\"fake_api_key\", model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_call_count = 0\n",
    "\n",
    "def agent(input: list[HumanMessage]):\n",
    "    return input\n",
    "\n",
    "def joke_finder(input: list[HumanMessage]):\n",
    "    global joke_call_count\n",
    "    joke_call_count += 1\n",
    "    print(\"joke_call_count: \", str(joke_call_count))\n",
    "    print(llm.invoke(input).content)\n",
    "    #print(chatModel.invoke(input).content)\n",
    "    return input\n",
    "\n",
    "\n",
    "def router_node1_to_node2(input: list[HumanMessage]):\n",
    "    if joke_call_count < 5:\n",
    "        return \"tell_joke\"\n",
    "    else:\n",
    "        return \"end_joke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = MessageGraph()\n",
    "\n",
    "node1_id = \"agent\"\n",
    "node2_id = \"joke_finder\"\n",
    "\n",
    "graph.add_node(node1_id, agent)\n",
    "graph.add_node(node2_id, joke_finder)\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    node1_id,\n",
    "    router_node1_to_node2,\n",
    "    {\"tell_joke\": node2_id, \"end_joke\": END}\n",
    ")\n",
    "graph.add_edge(node2_id, node1_id)\n",
    "graph.set_entry_point(node1_id)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph(runnable_graph, file_path):\n",
    "    png_out = runnable_graph.get_graph().draw_mermaid_png()\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(png_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_graph(app,\"third4_run.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
