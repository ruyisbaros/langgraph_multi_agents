{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END, MessageGraph\n",
    "from IPython.display import display, Image\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "import operator\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "llm = ChatGroq(\n",
    "    # model=\"llama3-groq-70b-8192-tool-use-preview\",\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "#embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "config = {\"configurable\": {\"thread_id\": 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry(input: list[HumanMessage]):\n",
    "    return input\n",
    "\n",
    "def human(input: list[HumanMessage]):\n",
    "    input[0].content += \" is not Amazing!\"\n",
    "    return input\n",
    "\n",
    "def ai(input: list[HumanMessage]):\n",
    "    input[0].content += \" is Amazing!\"\n",
    "    return input\n",
    "\n",
    "def finish(input: list[HumanMessage]):\n",
    "    input[0].content += \" always!\"\n",
    "    return input\n",
    "\n",
    "def router_node2_or_3(input: list[HumanMessage]):\n",
    "    if input[0].content == \"human\":\n",
    "        return \"human_node\"\n",
    "    else:\n",
    "        return \"ai_node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = MessageGraph()\n",
    "\n",
    "node1_id = \"entry\"\n",
    "node2_id = \"human\"\n",
    "node3_id = \"ai\"\n",
    "node4_id = \"finish\"\n",
    "\n",
    "graph.add_node(node1_id, entry)\n",
    "graph.add_node(node2_id, human)\n",
    "graph.add_node(node3_id, ai)\n",
    "graph.add_node(node4_id, finish)\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    node1_id,\n",
    "    router_node2_or_3,\n",
    "    {\"human_node\": node2_id, \"ai_node\": node3_id}\n",
    ")\n",
    "\n",
    "graph.add_edge(node2_id, node4_id)\n",
    "graph.add_edge(node3_id, node4_id)\n",
    "graph.add_edge(node4_id, END)\n",
    "graph.set_entry_point(node1_id)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph(runnable_graph, file_path):\n",
    "    png_out = runnable_graph.get_graph().draw_mermaid_png()\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(png_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_graph(app,\"second_run.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ai is Amazing! always!\n"
     ]
    }
   ],
   "source": [
    "print(app.invoke(\"Ai\")[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human is not Amazing! always!\n"
     ]
    }
   ],
   "source": [
    "print(app.invoke(\"human\")[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
